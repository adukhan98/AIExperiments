{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5d9A90rDg7yj3PhWCBf0L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adukhan98/AIExperiments/blob/main/Zephyr7B_chatbot_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš€ Installation of Dependencies: The notebook includes commands to install necessary Python packages like ***transformers*** and ***accelerate.***"
      ],
      "metadata": {
        "id": "M_ADvLkummLc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuVwyGOCls4V"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U accelerate jupyter ipywidgets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection: It sets up a dictionary (models_dict) with different model options, including ***\"Zephyr 7B Alpha\"*** and ***\"Zephyr 7B Beta\"***. The user can select a model by setting the model_id variable."
      ],
      "metadata": {
        "id": "KvYufDE4m4gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_dict = {\n",
        "    \"Zephyr 7B Alpha\": \"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "    \"Zephyr 7B Beta\": \"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    # You can add more chat/instruct models here\n",
        "}\n",
        "\n",
        "model_id = models_dict[\"Zephyr 7B Beta\"]"
      ],
      "metadata": {
        "id": "Eq5Qt8c6lxfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Initialization: **The notebook initializes the chosen model using the pipeline function from the transformers library, specifying parameters like torch_dtype and device_map."
      ],
      "metadata": {
        "id": "ncYLVCgjnvJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Running this may take a minute\n",
        "pipe = pipeline(\"text-generation\", model=model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "gk45-_4yl5UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining the Chatbot's Role: **A variable job_description is defined to set the role of the chatbot, in this case, a machine learning expert."
      ],
      "metadata": {
        "id": "NlZNA4oQoHbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = \"You are a fitness expert. Please answer my questions.\"\n",
        "#any role that you want to give it"
      ],
      "metadata": {
        "id": "eXQjtbMxl6gC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot Interaction Loop: The notebook sets up an interactive loop where the user can input questions, and the chatbot, based on the Zephyr 7B model, generates responses. The loop continues until the user inputs \"stop\" or \"exit\"."
      ],
      "metadata": {
        "id": "zQnSe1qzoR7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": job_description,\n",
        "    },\n",
        "]\n",
        "\n",
        "exit_terms = [\"stop\", \"exit\"]\n",
        "\n",
        "while True:\n",
        "    question = input(\"\\nQuestion: \")\n",
        "    if question.lower() in exit_terms:\n",
        "        break\n",
        "    messages.append({\"role\": \"user\", \"content\": question})\n",
        "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    outputs = pipe(prompt, max_new_tokens=512, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "    output = outputs[0][\"generated_text\"]\n",
        "    messages.append({\"role\": \"assistant\", \"content\": output})\n",
        "    response_start = output.rfind('<|assistant|>')\n",
        "    print(output[response_start + len('<|assistant|>'):])"
      ],
      "metadata": {
        "id": "Su45b0eKl-Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook provides a hands-on guide to setting up and interacting with a chatbot powered by a state-of-the-art language model, making it accessible for users to experiment with AI-driven conversational agents."
      ],
      "metadata": {
        "id": "A1-1Q19Xob7r"
      }
    }
  ]
}